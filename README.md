# Multi-Lingual Sentiment Analysis Competition  

## Results  
- **F1 Score:** 0.96551  
- **Leaderboard Position:** 5 (at the time of submission)  

## Competition Overview  
The goal of this competition was to explore fine-tuning as an art, specifically understanding how **LoRA-based parameter-efficient fine-tuning** can enhance the multilingual capabilities of a large-scale model like **LLaMA 3.1-8B**.  

Participants needed to balance:  
- **Data efficiency**  
- **Compute limitations** (Kaggle Notebooks only)  
- **Model adaptation techniques**  

The objective was to achieve **high sentiment classification accuracy** across **13 supported languages**, each represented in its **native script**.  
